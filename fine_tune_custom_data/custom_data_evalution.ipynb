{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fc129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, default_data_collator\n",
    "\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb996e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'TinyLLama/TinyLlama-1.1B-Chat-v1.0'\n",
    "adapter_path = './tinyllama-lora-tuned-adapter-frobinate'\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type = 'nf4',\n",
    "    bnb_4bit_compute_dtype = torch.bfloat16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config = bnb_config,\n",
    "    device_map = 'auto',\n",
    "    trust_remote_code = True\n",
    ").eval()\n",
    "\n",
    "tmp_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config = bnb_config,\n",
    "    device_map = 'auto',\n",
    "    trust_remote_code = True\n",
    ")\n",
    "\n",
    "tuned_model = PeftModel.from_pretrained(tmp_model, adapter_path)\n",
    "tuned_model = tuned_model.merge_and_unload().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b0c31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    texts = [\n",
    "        f\"### Instruction:\\n{inst}\\n### Response:\\n{out}\"\n",
    "        for inst, out in zip(batch['instruction'], batch['response'])\n",
    "    ]\n",
    "\n",
    "    tokens = tokenizer(\n",
    "        texts,\n",
    "        padding = 'max_length',\n",
    "        truncation = True,\n",
    "        max_length = 256,\n",
    "        return_tensors = 'pt'\n",
    "    )\n",
    "\n",
    "    tokens['labels'] = tokens['input_ids'].clone()\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9ba5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ds = load_dataset('json', data_files='frobinate.jsonl')['train']\n",
    "eval_ds = eval_ds.map(tokenize, batched=True, remove_columns=['instruction', 'response'])\n",
    "eval_ds = eval_ds.with_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ce8b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loader = DataLoader(\n",
    "    eval_ds,\n",
    "    batch_size = 8,\n",
    "    collate_fn = default_data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84294af",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def compute_perplexity(model):\n",
    "    losses = []\n",
    "    \n",
    "    for batch in eval_loader:\n",
    "        batch = {k: v.to('cuda') for k, v in batch.items()}\n",
    "        loss = model(**batch).loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return math.exp(sum(losses) / len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2262c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Base Model Perplexity: {compute_perplexity(base_model):.2f}')\n",
    "print(f'Tuned Model Perplexity: {compute_perplexity(tuned_model):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa32c5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "raw_data = load_dataset('json', data_files='frobinate.jsonl')['train']\n",
    "refs = raw_data['response']\n",
    "\n",
    "\n",
    "def generate(model, instruction):\n",
    "    token_ids = tokenizer(f'### Instruction:\\n{instruction}\\n### Response:\\n', return_tensors='pt').input_ids.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(token_ids, max_new_tokens=256)\n",
    "\n",
    "    #return tokenizer.decode(out[0], skip_special_tokens=True).split('### Response:\\n')[-1].strip()\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfe4178",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['instruction'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f89464",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate(base_model, raw_data['instruction'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3481a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate(tuned_model, raw_data['instruction'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd171f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(refs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda48dd2",
   "metadata": {},
   "source": [
    "UNSEEN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c060a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ds = load_dataset('json', data_files='frobinate_test.jsonl')['train']\n",
    "eval_ds = eval_ds.map(tokenize, batched=True, remove_columns=['instruction', 'response'])\n",
    "eval_ds = eval_ds.with_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d83ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loader = DataLoader(\n",
    "    eval_ds,\n",
    "    batch_size = 8,\n",
    "    collate_fn = default_data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9457ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Base Model Perplexity: {compute_perplexity(base_model):.2f}')\n",
    "print(f'Tuned Model Perplexity: {compute_perplexity(tuned_model):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4231d105",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = load_dataset('json', data_files='frobinate_test.jsonl')['train']\n",
    "refs = raw_data['response']\n",
    "\n",
    "\n",
    "def generate(model, instruction):\n",
    "    token_ids = tokenizer(f'### Instruction:\\n{instruction}\\n### Response:\\n', return_tensors='pt').input_ids.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(token_ids, max_new_tokens=256)\n",
    "\n",
    "    #return tokenizer.decode(out[0], skip_special_tokens=True).split('### Response:\\n')[-1].strip()\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0b14ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['instruction'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c847017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate(base_model, raw_data['instruction'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce44806",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate(tuned_model, raw_data['instruction'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff73e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(refs[0])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
